{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN031Yq5cbc/43Tik/Z3dr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riturajkumari/PCA/blob/main/PCA_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is a projection and how is it used in PCA?**"
      ],
      "metadata": {
        "id": "P6wRvG5wFCSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of correlated variables to a set of uncorrelated variables. It is used in exploratory data analysis and for making predictive models.\n",
        " - An important machine learning method for dimensionality reduction is called Principal Component Analysis.\n",
        "\n",
        "It is a method that uses simple matrix operations from linear algebra and statistics to calculate a projection of the original data into the same number or fewer dimensions."
      ],
      "metadata": {
        "id": "0x5SggKuLEqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Principal component analysis (PCA) is a popular technique for analyzing large datasets containing a high number of dimensions/features per observation, increasing the interpretability of data while preserving the maximum amount of information, and enabling the visualization of multidimensional data. Formally, PCA is a statistical technique for reducing the dimensionality of a dataset."
      ],
      "metadata": {
        "id": "veUac28SMGsm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYp5bVTkD8sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. How does the optimization problem in PCA work, and what is it trying to achieve?**"
      ],
      "metadata": {
        "id": "CbXMFcpFFQzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PCA stands for Principal Component Analysis. It is a statistical technique that is used to reduce the dimensionality of a dataset while retaining as much of the original variation as possible. PCA works by finding the linear combinations of the original variables that capture the most variation in the data. These linear combinations are called principal components."
      ],
      "metadata": {
        "id": "3UJg5R8CMb_3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfYK7nsRD8xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. What is the relationship between covariance matrices and PCA?**"
      ],
      "metadata": {
        "id": "tPwLHwIIFVci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Covariance matrices and correlation matrices are used in principal component analysis (PCA) to find the components. The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the “core” of a PCA. The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. The correlation matrix is used when variables are on different scales, while the covariance matrix is used when the variable scales are similar. PCA with and without standardizing will give different results."
      ],
      "metadata": {
        "id": "bf_eAUh3OSj-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlF-1iTLD820"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. How does the choice of number of principal components impact the performance of PCA?**"
      ],
      "metadata": {
        "id": "ex-D8F6PFZZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The number of principal components (PCs) chosen for PCA can impact the performance of PCA. Reducing the number of dimensions can increase the dataset’s manageability and computational efficiency. By identifying the principal components that explain the most variation in the data, PCA reduces redundant information by creating a set of entirely uncorrelated components."
      ],
      "metadata": {
        "id": "j9ILmyz5OlYj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2S2VxXxFc8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?**"
      ],
      "metadata": {
        "id": "QuMFWWkgFdJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Principal Components Analysis (PCA) is a well-known unsupervised dimensionality reduction technique that constructs relevant features/variables through linear (linear PCA) or non-linear (kernel PCA) combinations of the original variables (features).\n",
        "- The construction of relevant features is achieved by linearly transforming correlated variables into a smaller number of uncorrelated variables. This is done by projecting (dot product) the original data into the reduced PCA space using the eigenvectors of the covariance/correlation matrix  the principal components."
      ],
      "metadata": {
        "id": "YeWFzpSaVEGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The resulting projected data are essentially linear combinations of the original data capturing most of the variance in the data ."
      ],
      "metadata": {
        "id": "zp80v7lUV2C7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    - PCA technique is particularly useful in processing data where multi-colinearity exists between the features/variables.\n",
        "    - PCA can be used when the dimensions of the input features are high (e.g. a lot of variables).\n",
        "    - PCA can be also used for denoising and data compression."
      ],
      "metadata": {
        "id": "NjaXjAWwWzOE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6ef8lEVFg7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. What are some common applications of PCA in data science and machine learning?**"
      ],
      "metadata": {
        "id": "xqiolI10Fj3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Applications of PCA in Machine Learning\n",
        "    - PCA is used to visualize multidimensional data.\n",
        "    - It is used to reduce the number of dimensions in healthcare data.\n",
        "    - PCA can help resize an image.\n",
        "    - It can be used in finance to analyze stock data and forecast returns.\n",
        "    - PCA helps to find patterns in the high-dimensional datasets.\n"
      ],
      "metadata": {
        "id": "q516-UFaXIPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA is a widely used technique in data analysis and has a variety of applications, including:**\n",
        "\n",
        "  - Data compression: PCA can be used to reduce the dimensionality of    high-dimensional datasets, making them easier to store and analyze.\n",
        "  - Feature extraction: PCA can be used to identify the most important features in a dataset, which can be used to build predictive models.\n",
        "  - Visualization: PCA can be used to visualize high-dimensional data in two or three dimensions, making it easier to understand and interpret.\n",
        "  - Data pre-processing: PCA can be used as a pre-processing step for other machine learning algorithms, such as clustering and classification.\n"
      ],
      "metadata": {
        "id": "HqqWdMlGXu4P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yx47s5ZED8-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.What is the relationship between spread and variance in PCA?**"
      ],
      "metadata": {
        "id": "d_kSvbNcFnh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Variance: Variance is the spread of the data in a dataset. In PCA, the variables are transformed in such a way that they explain variance of the dataset in decreasing manner.\n",
        "\n",
        "- Principal Component Analysis can be used in Image compression. Image can be resized as per the requirement and patterns can be determined.\n",
        "- Principal Component Analysis helps in Customer profiling based on demographics as well as their intellect in the purchase.\n",
        "- PCA is a technique that is widely used by researchers in the food science field.\n",
        "- It can also be used in the Banking field in many areas like applicants applied for loans, credit cards, etc.\n",
        "Customer Perception towards brands.\n",
        "- It can also be used in the Finance field to analyze stocks quantitatively, forecasting portfolio returns, also in the interest rate implantation.\n",
        "- PCA is also applied in Healthcare industries in multiple areas like patient insurance data where there are multiple sources of data and with a huge number of variables that are correlated to each other. Sources are like hospitals, pharmacies, et"
      ],
      "metadata": {
        "id": "cApQPc8boMNj"
      }
    }
  ]
}